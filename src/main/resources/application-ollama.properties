# Ollama Configuration
spring.ai.ollama.base-url=http://localhost:11434
spring.ai.ollama.model=deepseek-r1:latest

# If you need a different model, change it here
# Common models: llama3, mistral, gemma, qwen, llava
